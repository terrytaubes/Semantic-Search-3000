A stochastic grammar (statistical grammar) is a grammar framework with a probabilistic notion of grammaticality:
Stochastic context-free grammar
Statistical parsing
Data-oriented parsing
Hidden Markov model
Estimation theory
Statistical natural language processing uses stochastic, probabilistic and statistical methods, especially to resolve difficulties that arise because longer sentences are highly ambiguous when processed with realistic grammars, yielding thousands or millions of possible analyses. Methods for disambiguation often involve the use of corpora and Markov models. "A probabilistic model consists of a non-probabilistic model plus some numerical quantities; it is not true that probabilistic models are inherently simpler or less structural than non-probabilistic models."
The technology for statistical NLP comes mainly from machine learning and data mining, both of which are fields of artificial intelligence that involve learning from data.


== Examples ==
A probabilistic method for rhyme detection is implemented by Hirjee & Brown in their study in 2013 to find internal and imperfect rhyme pairs in rap lyrics. The concept is adapted from a sequence alignment technique using BLOSUM (BLOcks SUbstitution Matrix). They were able to detect rhymes undetectable by non-probabilistic model.


== See also ==
Colorless green ideas sleep furiously
Computational linguistics
L-system#Stochastic grammars


== References ==


== Further reading ==
Christopher D. Manning, Hinrich Sch√ºtze: Foundations of Statistical Natural Language Processing, MIT Press (1999), ISBN 978-0-262-13360-9.
Stefan Wermter, Ellen Riloff, Gabriele Scheler (eds.): Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing, Springer (1996), ISBN 978-3-540-60925-4.
Pirani, Giancarlo, ed. Advanced algorithms and architectures for speech understanding. Vol. 1. Springer Science & Business Media, 2013.